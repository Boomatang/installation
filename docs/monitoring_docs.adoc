== Integreatly monitoring 
The following document will cover different aspects of Integreatly monitoring.

== Intended audience and prerequisites
The document is intended for the following users:

* SRE managing integreatly cluster
* Integreatly users:
** Workshop user
** RHMI customer
* Developers or users of individual components of Integreatly e.g Fuse/Syndesis
* Developers of integreatly:
** RH engineering
** Upstream contributor

Its assumed that the reader knows about Integreatly, what it is and what Integreatly consists of.

NOTE: Certain dashboards and alerts may not be visible if users don't have appropriate permissions.


:toc:


== Middleware Monitoring Architecture
In the middleware monitoring architecture there are two monitoring stacks available.

=== OpenShift Monitoring Stack
This stack gathers metrics from kube-state-metrics & node_exporter. These metrics give state information about kubernetes resources, and container metrics like cpu, memory & volumes across all nodes in the kubernetes cluster.

=== Middleware Monitoring Stack
The middleware monitoring stack comprises of Prometheus, Alertmanager & Grafana. All managed by the application-monitoring-operator.

==== Prometheus
Prometheus is configured to scrape metrics from various services across the middleware namespaces. It is also configured with Alerts, based on these metrics.

==== AlertManager
AlertManager receives any active alerts from Prometheus, and sends them to configured receivers based on the severity. Only currently active alerts will appear in AlertManger's web console.

==== Grafana
Grafana is configured via the Grafana Operator with dashboards from middleware namespaces. It leverages the GrafanaDashboard custom resource.

Middleware Services need to satisfy some criteria for metrics to be scraped:

* The namespace has a specific label with a specific value i.e. `monitoring-key=middleware`. This is to ensure we only monitor the namespaces we care about.
* The namespace has a ServiceMonitor resource that defines the Services or Pods to scrape metrics from. This ServiceMonitor must also have a label of `monitoring-key=middleware` on it.

== Navigating to the monitoring stack resources through the UI
1. Login into your clusters Openshift master console.
2. Navigate to my projects and click view all.
3. From there navigate to Managed service monitoring
4. This will provide information on other resources in the monitoring stack including pods memory, CPU and network.
5. From here you will be able to access the following:
* Grafana dashboard
* Alertmanager dashboard
* Prometheus dashboard.
6. You will also be able to access the operators:
* Grafana operator
* Prometheus operator
* Alertmanager application-monitoring

=== Permissions:
A users permissions are checked to see if the have access to the monitoring stack. How the users are checked is the following:

* A users permissions are checked using SAR which stands for ~Subject Access Review". SAR is a request sent to the Openshift server checking the access for said user. The SAR expects a single SAR JSON object or array which for the user to be allowed access the backend server must be satisfied. If the user can get namespaces then the pass the review and have permission to the monitoring stack. This can be checked via the UI or by this command `oc get namespaces`

* Authentication is skipped if the users has access to urls that start with /metrics


== Navigating to the monitoring stack through the CLI
=== Prometheus
To navigate to the Prometheus web console using the exposed route use the following
```
oc get route prometheus-route -n openshift-middleware-monitoring -o template --template "https://{{.spec.host}}"

```
=== Grafana
To navigate to the grafana web console using the exposed route use the following
```
oc get route grafana-route -n openshift-middleware-monitoring -o template --template "https://{{.spec.host}}"
```

=== AlertManager
To navigate to the AlertManager web console using the exposed route use the following
```
oc get route alertmanager-route -n openshift-middleware-monitoring -o template --template "https://{{.spec.host}}"
```


== What metrics are available in the monitoring stack?

=== Kube state metrics
Kube-state-metrics is a simple service that listens to the Kubernetes API server and generates metrics about the state of the objects. It is not focused on the health of the individual Kubernetes components, but rather on the health of the various objects inside, such as deployments, nodes and pods.

Kube-state-metrics is about generating metrics from Kubernetes API objects without modification. This ensures that features provided by kube-state-metrics have the same grade of stability as the Kubernetes API objects themselves. In turn, this means that kube-state-metrics in certain situations may not show the exact same values as kubectl, as kubectl applies certain heuristics to display comprehensible messages. Kube-state-metrics exposes raw data unmodified from the Kubernetes API, this way users have all the data they require and perform heuristics as they see fit.

The metrics are exported on the HTTP endpoint /metrics on the listening port (default 80). They are served as plaintext. They are designed to be consumed either by Prometheus itself or by a scraper that is compatible with scraping a Prometheus client endpoint. You can also open /metrics in a browser to see the raw metrics.

Exposed metrics:
Per group of metrics there is one file for each metrics. See each file for specific documentation about the exposed metrics:
https://github.com/kubernetes/kube-state-metrics/tree/master/docs

=== Node-exporter metrics
The node exporter runs on every node in the openshift cluster gathering metrics about everything on that node and then sending the information back to prometheus.The metrics have a node="whatever-ip" label on them so you know which node the information came from. The node exporter for hardware and OS metrics exposed by *NIX kernels, written in Go with pluggable metric collectors.

Enabled and disabled by default:
To see the list of what is exposed or not exposed by default follow the following link:
https://github.com/prometheus/node_exporter#collectors


== How are metrics calculated?

== What alerting is available?

== How is alerting setup?

== Who can access the monitoring stack?






